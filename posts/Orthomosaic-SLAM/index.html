<!DOCTYPE html>
<html lang="en-US" 
>
<head>
 <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
 <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Aerial Navigation in GPS Denied Environments" />
<meta name="author" content="Jai Krishna" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A portfolio of my adventures in robotics, electronics and mechanical along with tutorials on topics related to robotics." />
<meta property="og:description" content="A portfolio of my adventures in robotics, electronics and mechanical along with tutorials on topics related to robotics." />
<link rel="canonical" href="https://textzip.github.io/posts/Orthomosaic-SLAM/" />
<meta property="og:url" content="https://textzip.github.io/posts/Orthomosaic-SLAM/" />
<meta property="og:site_name" content="Jai Krishna" />
<meta property="og:image" content="https://textzip.github.io/assets/img/OrthomosaicSLAM/campus_data.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-10-18T19:13:20+05:30" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://textzip.github.io/assets/img/OrthomosaicSLAM/campus_data.png" />
<meta property="twitter:title" content="Aerial Navigation in GPS Denied Environments" />
<meta name="twitter:site" content="@twitter_username" />
<meta name="twitter:creator" content="@Jai Krishna" />
<meta name="google-site-verification" content="google_meta_tag_verification" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Jai Krishna"},"dateModified":"2022-01-18T16:36:00+05:30","datePublished":"2021-10-18T19:13:20+05:30","description":"A portfolio of my adventures in robotics, electronics and mechanical along with tutorials on topics related to robotics.","headline":"Aerial Navigation in GPS Denied Environments","image":"https://textzip.github.io/assets/img/OrthomosaicSLAM/campus_data.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://textzip.github.io/posts/Orthomosaic-SLAM/"},"url":"https://textzip.github.io/posts/Orthomosaic-SLAM/"}</script>
 <title>Aerial Navigation in GPS Denied Environments | Jai Krishna
 </title>
<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">
<link rel="manifest" href="/assets/img/favicons/site.webmanifest">
<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="Jai Krishna">
<meta name="application-name" content="Jai Krishna">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="/assets/css/slider/ideal-image-slider.css">
<link rel="stylesheet" href="/assets/css/slider/themes/default.css">
  <script src="/assets/js/slider/ideal-image-slider.min.js"></script>
  <script src="/assets/js/slider/iis-bullet-nav.js"></script>
  <script src="/assets/js/slider/iis-captions.js"></script>
  <script>
  var orthoslam = new IdealImageSlider.Slider({
      selector: '#orthoslam',
      height: 600,
      interval: 4000,
      effect: 'slide',
      keyboardNav: true,
      });
    orthoslam.addCaptions();
    orthoslam.start();
  </script>
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous">
<link rel="dns-prefetch" href="https://fonts.gstatic.com">
  <link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials">
  <link rel="dns-prefetch" href="https://www.google-analytics.com">
  <link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous">
  <link rel="dns-prefetch" href="https://www.googletagmanager.com">
<link rel="preconnect" href="https://cdn.jsdelivr.net">
<link rel="dns-prefetch" href="https://cdn.jsdelivr.net">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css">
<link rel="stylesheet" href="/assets/css/style.css">
<link rel="stylesheet"
    href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css">
  <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script defer
    src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script>
  <script async
    src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js"></script>
<script defer src="/assets/js/dist/post.min.js"></script>
  <script defer src="/app.js"></script>
<script
  async
  src="https://www.googletagmanager.com/gtag/js?id=G-KGYYX7MFB2"
></script>
<script>
  /* global dataLayer */
  window.dataLayer = window.dataLayer || [];
  function gtag() {
    dataLayer.push(arguments);
  }
  gtag("js", new Date());
  gtag("config", "G-KGYYX7MFB2");
</script>
 <body data-spy="scroll" data-target="#toc">
<div id="sidebar" class="d-flex flex-column align-items-end">
 <div class="profile-wrapper text-center">
   <div id="avatar">
      <a href="/" alt="avatar" class="mx-auto">
        <img src="/assets/img/profile.jpg" alt="avatar" onerror="this.style.display='none'">
      </a>
   </div>
   <div class="site-title mt-3">
      <a href="/">Jai Krishna</a>
   </div>
   <div class="site-subtitle font-italic">Robotics | Electronics | Design</div>
 </div>
 <ul class="w-100">
   <li class="nav-item">
      <a href="/" class="nav-link">
        <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i>
        <span>HOME</span>
      </a>
   <li class="nav-item">
      <a href="/projects/" class="nav-link">
        <i class="fa-fw fas fa-microchip ml-xl-3 mr-xl-3 unloaded"></i>
        <span>PROJECTS</span>
      </a>
   <li class="nav-item">
      <a href="/resources/" class="nav-link">
        <i class="fa-fw fas fa-chalkboard-teacher ml-xl-3 mr-xl-3 unloaded"></i>
        <span>RESOURCES</span>
      </a>
   <li class="nav-item">
      <a href="/categories/" class="nav-link">
        <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i>
        <span>CATEGORIES</span>
      </a>
   <li class="nav-item">
      <a href="/archives/" class="nav-link">
        <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i>
        <span>ARCHIVES</span>
      </a>
   <li class="nav-item">
      <a href="/about/" class="nav-link">
        <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i>
        <span>ABOUT | CONTACT</span>
      </a>
   <li class="nav-item">
      <a href="/tags/" class="nav-link">
        <i class="fa-fw fas fa-chalkboard-teacher ml-xl-3 mr-xl-3 unloaded"></i>
        <span>TAGS</span>
      </a>
 </ul>
 <div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center">
      <a href="https://github.com/TextZip" aria-label="github"
        class="order-3"
        target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
      <a href="
          javascript:location.href = 'mailto:' + ['textzip','gmail.com'].join('@')" aria-label="email"
        class="order-4"
        >
        <i class="fas fa-envelope"></i>
      </a>
      <a href="https://www.linkedin.com/in/jai-krishna-bandi" aria-label="linkedin"
        class="order-5"
        target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
        <span class="icon-border order-2"></span>
      <span id="mode-toggle-wrapper" class="order-1">
<i class="mode-toggle fas fa-adjust"></i>
<script type="text/javascript">
  class ModeToggle {
    static get MODE_KEY() { return "mode"; }
    static get DARK_MODE() { return "dark"; }
    static get LIGHT_MODE() { return "light"; }
    constructor() {
      if (this.hasMode) {
        if (this.isDarkMode) {
          if (!this.isSysDarkPrefer) {
            this.setDark();
          }
        } else {
          if (this.isSysDarkPrefer) {
            this.setLight();
          }
        }
      }
      var self = this;
      /* always follow the system prefers */
      this.sysDarkPrefers.addListener(function() {
        if (self.hasMode) {
          if (self.isDarkMode) {
            if (!self.isSysDarkPrefer) {
              self.setDark();
            }
          } else {
            if (self.isSysDarkPrefer) {
              self.setLight();
            }
          }
          self.clearMode();
        }
        self.updateMermaid();
      });
    } /* constructor() */
    setDark() {
      $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
    }
    setLight() {
      $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
    }
    clearMode() {
      $('html').removeAttr(ModeToggle.MODE_KEY);
      sessionStorage.removeItem(ModeToggle.MODE_KEY);
    }
    get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); }
    get isSysDarkPrefer() { return this.sysDarkPrefers.matches; }
    get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; }
    get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; }
    get hasMode() { return this.mode != null; }
    get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); }
    /* get the current mode on screen */
    get modeStatus() {
      if (this.isDarkMode
        || (!this.hasMode && this.isSysDarkPrefer) ) {
        return ModeToggle.DARK_MODE;
      } else {
        return ModeToggle.LIGHT_MODE;
      }
    }
    updateMermaid() {
      if (typeof mermaid !== "undefined") {
        let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default");
        let config = { theme: expectedTheme };
        /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */
        $(".mermaid").each(function() {
          let svgCode = $(this).prev().children().html();
          $(this).removeAttr("data-processed");
          $(this).html(svgCode);
        });
        mermaid.initialize(config);
        mermaid.init(undefined, ".mermaid");
      }
    }
    flipMode() {
      if (this.hasMode) {
        if (this.isSysDarkPrefer) {
          if (this.isLightMode) {
            this.clearMode();
          } else {
            this.setLight();
          }
        } else {
          if (this.isDarkMode) {
            this.clearMode();
          } else {
            this.setDark();
          }
        }
      } else {
        if (this.isSysDarkPrefer) {
          this.setLight();
        } else {
          this.setDark();
        }
      }
      this.updateMermaid();
    } /* flipMode() */
  } /* ModeToggle */
  let toggle = new ModeToggle();
  $(".mode-toggle").click(function() {
    toggle.flipMode();
  });
</script>
      </span>
 </div>
</div>
<div id="topbar-wrapper" class="row justify-content-center topbar-down">
 <div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between">
    <span id="breadcrumb">
        <span>
          <a href="/">
            Posts
          </a>
        </span>
          <span>Aerial Navigation in GPS Denied Environments</span>
    </span>
    <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i>
   <div id="topbar-title">
      Post
   </div>
    <i id="search-trigger" class="fas fa-search fa-fw"></i>
    <span id="search-wrapper" class="align-items-center">
      <i class="fas fa-search fa-fw"></i>
      <input class="form-control" id="search-input" type="search"
        aria-label="search" autocomplete="off" placeholder="Search...">
      <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i>
    </span>
    <span id="search-cancel" >Cancel</span>
 </div>
</div>
   <div id="main-wrapper">
     <div id="main">
<div class="row">
 <div id="post-wrapper" class="col-12 col-lg-11 col-xl-8">
   <div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4">
     <h1 data-toc-skip>Aerial Navigation in GPS Denied Environments</h1>
     <div class="post-meta text-muted d-flex flex-column">
       <div>
          <span class="semi-bold">
            Bandi Jai Krishna
          </span>
<em class="timeago"
    data-ts="1634564600"
      data-toggle="tooltip" data-placement="bottom" 
      title="Mon, Oct 18, 2021,  7:13 PM +0530"
    >
  2021-10-18
</em>
       </div>
       <div>
          <span>
<em class="timeago lastmod"
    data-ts="1642503960"
      data-toggle="tooltip" data-placement="bottom" 
      title="Tue, Jan 18, 2022,  4:36 PM +0530"
    >
  2022-01-18
</em>
          </span>
<span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2178 words">12 min</span>
       </div>
     </div>
     <div class="post-content">
       <p><img src="/assets/img/OrthomosaicSLAM/campus_data.png" alt="Image1" class="shadow" /></p>
<p>A project on achieving realtime-orthomosaic SLAM for aerial navigation using a single downwards facing camera in outdoor GPS denied environments.</p>
<h1 id="results">Results</h1>
<div id="orthoslam">
  <img data-src="" data-src-2x="" src="/assets/img/OrthomosaicSLAM/city_input.jpg" title="" alt="City Input" />
  <img data-src="" data-src-2x="" src="/assets/img/OrthomosaicSLAM/city_output.png" title="" alt="City Output" />
  <img data-src="" data-src-2x="" src="/assets/img/OrthomosaicSLAM/lake_nornal_input.jpg" title="" alt="Forest 1 Input" />
  <img data-src="" data-src-2x="" src="/assets/img/OrthomosaicSLAM/lake_normal_output.png" title="" alt="Forest 1 Output" />
  <img data-src="" data-src-2x="" src="/assets/img/OrthomosaicSLAM/extended_lake_input.jpg" title="" alt="Forest 2 Input" />
  <img data-src="" data-src-2x="" src="/assets/img/OrthomosaicSLAM/lake_extended_output.png" title="" alt="Forest 2 Output" />
 </div>
<h1 id="introduction">Introduction</h1>
<p>To carry out drone-based aerial surveying for generating orthomosaic maps on the fly, this project explores the image processing stack required to achieve the same using the most economical hardware and software footprint. The project explores corner and blob-based feature extraction techniques followed by brute force and KNN based feature matching methods which are later used to generate a homography matrix for stitching images passed through a cascaded image mixer to generate orthomosaic maps of a given dataset.</p>
<p><a href="https://github.com/TextZip/OrthomosaicSLAM"><img src="https://gh-card.dev/repos/TextZip/OrthomosaicSLAM.svg" alt="TextZip/OrthomosaicSLAM - GitHub" /></a></p>
<h1 id="feature-detection--extraction">Feature Detection &amp; Extraction</h1>
<p>While there is no universally accepted definition of “Feature” for a given image, it is often regarded as the information that is unique for the given image and thus helps us mathematically associate the image with its unique data properties.</p>
<p><img src="/assets/img/OrthomosaicSLAM/features.png" alt="Image1" class="shadow" /></p>
<p>Image Features are small patches of unique raw data that can be potentially used to differentiate the given image from any other image, therefore, helping in tracking the similarity between given images. Image Features can be broken down into two major components:</p>
<p>1) Keypoints
2) Descriptor</p>
<p>They are explained in the subsequent sections.</p>
<h2 id="keypoints">Keypoints</h2>
<p>Keypoints contain 2D patch data like position, scale, convergence area, and other properties of the local patch. Which we define as a distinctive point in an input image that is invariant to rotation, scale, and distortion. In practice, the key points are not perfectly invariant but they are a good approximation. [1]</p>
<p><img src="/assets/img/OrthomosaicSLAM/hand.png" alt="Image1" class="shadow" />
<em>Example: Keypoints of a human hand.</em></p>
<h2 id="descriptors--detectors">Descriptors &amp; Detectors</h2>
<p>A feature detector is an algorithm that takes an image and produces the positions (pixel coordinates) of important regions in the picture. A corner detector is an illustration of this, since it outputs the positions of corners in your picture but does not provide any other information about the features discovered.</p>
<p>A feature descriptor is an algorithm that takes an image and generates feature descriptors/feature vectors from it.[2] Feature descriptors encapsulate important information into a sequence of numbers and serve as a numerical “fingerprint” that may be used to distinguish one feature from another. They highlight various keypoint properties in vector format (constant length). It might be their intensity in the direction of their most pronounced orientation, for example. It is giving a numerical description of the area of the image to which the keypoint is referenced.</p>
<p>Important properties of descriptors</p>
<ul>
 <li>
   <p>they should be independent of keypoint position
If the same keypoint is extracted at different positions (e.g. because of translation) the descriptor should be the same. [3]</p>
 <li>they should be robust against image transformations
Variations in contrast (for example, a photograph of the same location on a bright and overcast day) and changes in perspective are two examples (image of a building from center-right and center-left, we would still like to recognize it as the same building). Of all, no description is absolutely impervious to all modifications (nor against any single one if it is strong, e.g. big change in perspective). Different descriptors are meant to be resistant against various transformations, which are sometimes incompatible with the speed at which they are calculated. [3]
 <li>they should be scale independent
The scale should be considered in the descriptions. If the “prominent” component of one key point is a vertical line of 10px (within a circular area with a radius of 8px), and the prominent part of another is a vertical line of 5px (inside a circular area with a radius of 4px), the descriptions for both key points should be identical. [3]
</ul>
<h2 id="available-methods">Available Methods</h2>
<h3 id="shi-tomasi-corner-detector">Shi-Tomasi Corner Detector</h3>
<p><img src="/assets/img/OrthomosaicSLAM/campus1.png" alt="Image1" class="shadow" /></p>
<p>Example: Using Good Features to Track to detect keypoints</p>
<p>The Shi-Tomasi Corner Detector is a modified version of the Harris Corner Detector with the primary change being in the way in which the score “R” is calculated making it more efficient than the standard Harris Corner Detector.</p>
<p>Corners are considered as areas in photographs where a little alteration in position, results in a significant change in intensity in both the horizontal (X) and vertical (Y) axes.</p>
<p>The Pseudocode for Shi-Tomasi Corner Detector:</p>
<ol>
 <li>Determine windows of small image patches that produce very large variations in intensity when moved in both X and Y directions (i.e. gradients).[4]
 <li>Compute score R for each such window.
3, Apply a threshold to select and retrieve important corner points.
</ol>
<p>Python Implementation of Shi-Tomasi Corner Detector:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">img_1</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="sh">'</span><span class="s">images/admin_block.jpg</span><span class="sh">'</span><span class="p">)</span>
<span class="n">gray</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">cvtColor</span><span class="p">(</span><span class="n">img_1</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">namedWindow</span><span class="p">(</span><span class="sh">"</span><span class="s">output</span><span class="sh">"</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">WINDOW_NORMAL</span><span class="p">)</span>
<span class="n">corners</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">goodFeaturesToTrack</span><span class="p">(</span><span class="n">gray</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">corners</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">int0</span><span class="p">(</span><span class="n">corners</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">corners</span><span class="p">:</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">i</span><span class="p">.</span><span class="nf">ravel</span><span class="p">()</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">circle</span><span class="p">(</span><span class="n">img_1</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="mi">3</span><span class="p">,</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">"</span><span class="s">output</span><span class="sh">"</span><span class="p">,</span> <span class="n">img_1</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">destroyAllWindows</span><span class="p">()</span>
</pre></table></code></div></div>
<p>OpenCV has implemented a function cv2.goodFeaturesToTrack() the parameters for this function are:</p>
<ul>
 <li><strong>image</strong> - Input 8-bit or floating-point 32-bit, single-channel image
 <li><strong>maxCorners</strong> - Maximum number of corners to detect. If the number of corners on an image is higher than the number of maxCorners the most pronounced corners are selected.
 <li><strong>qualityLevel</strong> - Parameter characterizing the minimal accepted quality of image corners. All corners below the quality level are rejected. The parameter value is multiplied by the best corner quality measure, which is the minimal eigenvalue of the Harris function response.[5]
 <li><strong>minDistance</strong> - minimal Euclidean distance between corners
</ul>
<h3 id="scale-invariant-feature-transform-sift">Scale Invariant Feature Transform (SIFT)</h3>
<p><img src="/assets/img/OrthomosaicSLAM/campus2.png" alt="Image1" class="shadow" />
<em>Example: Using SIFT to detect keypoints</em></p>
<p>SIFT, which stands for Scale-Invariant Feature Transform, was introduced in 2004 by D.Lowe of the University of British Columbia. This algorithm is robust against image scale variations and rotation invariances.</p>
<p>The Pseudocode for SIFT:</p>
<ol>
 <li>Scale-space peak selection: Potential location for finding features.
 <li>Keypoint Localization: Accurately locating the feature keypoints.
 <li>Orientation Assignment: Assigning orientation to keypoints.
 <li>Keypoint descriptor: Describing the keypoints as a high dimensional vector.
 <li>Keypoint Matching
</ol>
<p>The Python Implementation for SIFT:
</p>
<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">imread</span><span class="sh">'</span><span class="s">(images/admin_block.jpg</span><span class="sh">'</span><span class="p">)</span>
<span class="n">img_gray</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BRG2GRAY</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">namedWindow</span><span class="p">(</span><span class="sh">"</span><span class="s">output</span><span class="sh">"</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">WINDOW_NORMAL</span><span class="p">)</span>
<span class="n">sift</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nc">SIFT_create</span><span class="p">()</span>
<span class="n">kypoints</span> <span class="o">=</span> <span class="n">sift</span><span class="p">.</span><span class="nf">detect</span><span class="p">(</span><span class="n">img_gray</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">"</span><span class="s">output</span><span class="sh">"</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">drawKeypoints</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">keypoints</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">)))</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">destroyAllWindows</span><span class="p">()</span>
</pre></table></code></div></div>
<p>Parameters for SIFT:</p>
<ul>
 <li><strong>nfeatures</strong> - The number of best features to retain. The features are ranked by their scores (measured in SIFT algorithm as the local contrast)
 <li><strong>nOctaveLayers</strong> - The number of layers in each octave. 3 is the value used in D. Lowe’s paper. The number of octaves is computed automatically from the image resolution.
 <li><strong>contrastThreshold</strong> - The contrast threshold is used to filter out weak features in semi-uniform (low-contrast) regions. The larger the threshold, the fewer features are produced by the detector.
</ul>
<h3 id="speeded-up-robust-features-surf">Speeded Up Robust Features (SURF)</h3>
<p>The SURF (Speeded Up Robust Features) technique is a quick and robust approach for local, similarity invariant picture representation and comparison. The SURF approach’s prominent feature is its quick computing of operators using box filters, which enables real-time applications such as tracking and object identification.</p>
<p>The Pseducode for SURF:</p>
<ol>
 <li>Feature Extraction
   <ol>
     <li>Hessian matrix-based interest points
     <li>Scale-space representation
   </ol>
 <li>Feature Description
   <ol>
     <li>Orientation Assignment
     <li>Descriptor Components
   </ol>
</ol>
<p><img src="/assets/img/OrthomosaicSLAM/math.png" alt="Image1" class="shadow" /></p>
<p>The python implementation of SURF:
</p>
<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">imread</span><span class="sh">'</span><span class="s">(images/admin_block.jpg</span><span class="sh">'</span><span class="p">)</span>
<span class="n">img_gray</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BRG2GRAY</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">namedWindow</span><span class="p">(</span><span class="sh">"</span><span class="s">output</span><span class="sh">"</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">WINDOW_NORMAL</span><span class="p">)</span>
<span class="n">surf</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">xfeatures2d</span><span class="p">.</span><span class="nc">SURF_create</span><span class="p">()</span>
<span class="n">kypoints</span> <span class="o">=</span> <span class="n">surf</span><span class="p">.</span><span class="nf">detect</span><span class="p">(</span><span class="n">img_gray</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">"</span><span class="s">output</span><span class="sh">"</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">drawKeypoints</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">keypoints</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">)))</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">destroyAllWindows</span><span class="p">()</span>
</pre></table></code></div></div>
<p>public static SURF create​(double hessianThreshold, int nOctaves, int nOctaveLayers, boolean extended, boolean upright)</p>
<p>Parameters for SURF:</p>
<ul>
 <li><strong>hessianThreshold</strong> - Threshold for hessian keypoint detector used in SURF.
 <li><strong>nOctaves</strong> - Number of pyramid octaves the keypoint detector will use.
 <li><strong>nOctaveLayers</strong> - Number of octave layers within each octave.
 <li><strong>extended</strong> - Extended descriptor flag (true - use extended 128-element descriptors; false - use 64-element descriptors).
 <li><strong>upright</strong> - Up-right or rotated features flag (true - do not compute the orientation of features; false - compute orientation).
</ul>
<h3 id="oriented-fast-and-rotated-brief-orb">Oriented FAST and Rotated BRIEF (ORB)</h3>
<p><img src="/assets/img/OrthomosaicSLAM/campus3.png" alt="Image1" class="shadow" /></p>
<p>Example: Using ORB to detect keypoints</p>
<p>ORB is a combination of the FAST keypoint detector and the BRIEF descriptor, with some additional characteristics to boost performance. FAST stands for Features from Accelerated Segment Test, and it is used to find features in a picture. It also employs a pyramid to generate multiscale features.[2] It no longer computes the orientation and descriptors for the features, which is where BRIEF is used.</p>
<p>ORB employs BRIEF descriptors, although the BRIEF performs badly when rotated. So what ORB does is rotate the BRIEF according to the keypoint orientation. The rotation matrix of the patch is calculated using the patch’s orientation, and the BRIEF is rotated to obtain the rotated version.</p>
<p>The Pseudocode for ORB:[7]</p>
<ol>
 <li>Take the query image and convert it to grayscale.
 <li>Now Initialize the ORB detector and detect the keypoints in query image and scene.
 <li>Compute the descriptors belonging to both images.
 <li>Match the keypoints using Brute Force Matcher.
 <li>Show the matched images.
</ol>
<p>The Python implementation of ORB:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">imread</span><span class="sh">'</span><span class="s">(images/admin_block.jpg</span><span class="sh">'</span><span class="p">)</span>
<span class="n">img_gray</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BRG2GRAY</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">namedWindow</span><span class="p">(</span><span class="sh">"</span><span class="s">output</span><span class="sh">"</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">WINDOW_NORMAL</span><span class="p">)</span>
<span class="n">orb</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nc">ORB_create</span><span class="p">(</span><span class="n">nfeatures</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">kypoints_orb</span><span class="p">,</span> <span class="n">descriptors</span> <span class="o">=</span> <span class="n">orb</span><span class="p">.</span><span class="nf">detectAndCompute</span><span class="p">(</span><span class="n">img_1</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">"</span><span class="s">output</span><span class="sh">"</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">drawKeypoints</span><span class="p">(</span><span class="n">img_1</span><span class="p">,</span> <span class="n">keypoints_orb</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">)))</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">destroyAllWindows</span><span class="p">()</span>
</pre></table></code></div></div>
<h2 id="conclusion">Conclusion</h2>
<ul>
 <li>One of the notable drawbacks of the Shi-Tomasi Corner Detector is the fact that it is not scale-invariant.
 <li>ORB is a more efficient feature extraction approach than SIFT or SURF in terms of computing cost, matching performance, and, most importantly, patents.
 <li>SIFT and SURF are patented, and you are required to pay for their use. However, ORB is not patented.
   <h1 id="feature-matching">Feature Matching</h1>
   <h2 id="available-methods-1">Available Methods</h2>
   <h3 id="brute-force-matcher">Brute Force Matcher</h3>
   <p><img src="/assets/img/OrthomosaicSLAM/compare1.png" alt="Image1" class="shadow" /></p>
</ul>
<p>The Brute Force Matcher is used to compare the characteristics of the first image to those of another image.</p>
<p>It takes one of the first picture’s descriptors and matches it to all of the second image’s descriptors, then moves on to the second descriptor of the first image and matches it to all of the second image’s descriptors, and so on.</p>
<h1 id="homography--transformation">Homography &amp; Transformation</h1>
<p><img src="/assets/img/OrthomosaicSLAM/homography.png" alt="Image1" class="shadow" /></p>
<p>A homography connects any two photographs of the same scene. It is a transformation that transfers the points in one picture to the points in the other. The two pictures can be captured by rotating the camera along its optical axis or by laying them on the same surface in space.</p>
<p>The essence of the homography is the simple 3×3 matrix called the homography matrix.</p>
<p>This matrix may be applied to any spot in the picture. For example, in the first image, if we choose a position A(x1,y1), we may use a homography matrix to translate this point A to the matching point B(x2,y2) in the second image.
</p>
<p>The python implementation of finding homography matrix:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">wrap_images</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">image1</span><span class="p">,</span> <span class="n">image2</span><span class="p">,</span> <span class="n">H</span><span class="p">):</span>
    <span class="n">rows1</span><span class="p">,</span> <span class="n">cols1</span> <span class="o">=</span> <span class="n">image1</span><span class="p">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">rows2</span><span class="p">,</span> <span class="n">cols2</span> <span class="o">=</span> <span class="n">image2</span><span class="p">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">H</span> <span class="o">=</span> <span class="n">H</span>
    <span class="n">list_of_points_1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">float32</span><span class="p">(</span>
        <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">rows1</span><span class="p">],</span> <span class="p">[</span><span class="n">cols1</span><span class="p">,</span> <span class="n">rows1</span><span class="p">],</span> <span class="p">[</span><span class="n">cols1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">temp_points</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">float32</span><span class="p">(</span>
        <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">rows2</span><span class="p">],</span> <span class="p">[</span><span class="n">cols2</span><span class="p">,</span> <span class="n">rows2</span><span class="p">],</span> <span class="p">[</span><span class="n">cols2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="c1"># When we have established a homography we need to warp perspective
</span>    <span class="c1"># Change field of view
</span>    <span class="n">list_of_points_2</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">perspectiveTransform</span><span class="p">(</span><span class="n">temp_points</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
    <span class="n">list_of_points</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span>
        <span class="p">(</span><span class="n">list_of_points_1</span><span class="p">,</span> <span class="n">list_of_points_2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="p">[</span><span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">int32</span><span class="p">(</span><span class="n">list_of_points</span><span class="p">.</span><span class="nf">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">ravel</span><span class="p">()</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="p">[</span><span class="n">x_max</span><span class="p">,</span> <span class="n">y_max</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">int32</span><span class="p">(</span><span class="n">list_of_points</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">ravel</span><span class="p">()</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">translation_dist</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="n">x_min</span><span class="p">,</span> <span class="o">-</span><span class="n">y_min</span><span class="p">]</span>
    <span class="n">H_translation</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">translation_dist</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[</span>
        <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">translation_dist</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
    <span class="n">output_img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">warpPerspective</span><span class="p">(</span>
        <span class="n">image2</span><span class="p">,</span> <span class="n">H_translation</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">H</span><span class="p">),</span> <span class="p">(</span><span class="n">x_max</span><span class="o">-</span><span class="n">x_min</span><span class="p">,</span> <span class="n">y_max</span><span class="o">-</span><span class="n">y_min</span><span class="p">))</span>
    <span class="n">output_img</span><span class="p">[</span><span class="n">translation_dist</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span><span class="n">rows1</span><span class="o">+</span><span class="n">translation_dist</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">translation_dist</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">cols1</span><span class="o">+</span><span class="n">translation_dist</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">image1</span>
    <span class="k">return</span> <span class="n">output_img</span>
</pre></table></code></div></div>
<p>It is important to realize that feature matching does not always provide perfect matches. As a result, the Random Sample Consensus (RANSAC) process is used as a parameter in the cv2.findHomography() method, making the algorithm robust to outliers. We can get reliable results using this strategy even if we have a large percentage of bad matches.</p>
<h3 id="python-implementation-of-ransac">Python Implementation of RANSAC:</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre><td class="rouge-code"><pre><span class="c1"># Set minimum match condition
</span><span class="n">MIN_MATCH_COUNT</span> <span class="o">=</span> <span class="mi">2</span>
<span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">good</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">MIN_MATCH_COUNT</span><span class="p">:</span>
    <span class="c1"># Convert keypoints to an argument for findHomography
</span>    <span class="n">src_pts</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">float32</span><span class="p">(</span>
    <span class="p">[</span><span class="n">keypoints1</span><span class="p">[</span><span class="n">m</span><span class="p">.</span><span class="n">queryIdx</span><span class="p">].</span><span class="n">pt</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">good</span><span class="p">]).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">dst_pts</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">float32</span><span class="p">(</span>
    <span class="p">[</span><span class="n">keypoints2</span><span class="p">[</span><span class="n">m</span><span class="p">.</span><span class="n">trainIdx</span><span class="p">].</span><span class="n">pt</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">good</span><span class="p">]).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="c1"># Establish a homography
</span>    <span class="n">M</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">findHomography</span><span class="p">(</span><span class="n">src_pts</span><span class="p">,</span> <span class="n">dst_pts</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">RANSAC</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">wrap_images</span><span class="p">(</span><span class="n">image2</span><span class="p">,</span> <span class="n">image1</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
    <span class="c1"># cv2.imwrite('test4.jpg',result)
</span>    <span class="c1"># cv2.imshow("output_image",result)
</span>    <span class="c1"># cv2.waitKey(0)
</span>    <span class="c1"># cv2.destroyAllWindows()
</span>    <span class="k">return</span> <span class="n">result</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Error</span><span class="sh">"</span><span class="p">)</span>

</pre></table></code></div></div>
<h1 id="image-processing-pipeline">Image Processing Pipeline</h1>
<p><img src="/assets/img/OrthomosaicSLAM/code7.png" alt="Image1" class="shadow" /></p>
<h2 id="dataset">Dataset</h2>
<h3 id="urban-area">Urban Area</h3>
<p><img src="/assets/img/OrthomosaicSLAM/campus_data.png" alt="Image1" class="shadow" /></p>
<p>This dataset of the Thammasat University campus in Bangkok, Thailand was collected by a senseFly eBee X drone carrying a senseFly Aeria X photogrammetry camera.</p>
<p>Technical Details
|Feature|Value|
|–|–|
Ground resolution|6 cm (3.36 in)/px
Coverage|2.1 sq. km (0.77 sq. mi)
Flight height|285 m (935 ft)
Number of images|443</p>
<h3 id="forest-area">Forest Area</h3>
<p><img src="/assets/img/OrthomosaicSLAM/forest_data.png" alt="Image1" class="shadow" /></p>
<p>DroneMapper flew Greg 1 and 2 reservoirs on September 16th, 2019 using their Phantom 3 Advanced drone to collect imagery for precision digital elevation model (DEM) and orthomosaic generation of the site. GCP was surveyed with a Trimble 5800 and used during the image processing. Approximately 189 images were collected and processed via photogrammetry to yield the DEM, orthomosaic, and capacity report.[8]</p>
<div class="table-wrapper"><table>
<thead>
   <tr>
     <th>Feature
     <th>Value
 <tbody>
   <tr>
     <td>Ground resolution
     <td>6 cm (3.36 in)/px
   <tr>
     <td>Coverage
     <td>2.1 sq. km (0.77 sq. mi)
   <tr>
     <td>Flight height
     <td>285 m (935 ft)
   <tr>
     <td>Number of images
     <td>189
</table></div>
<h1 id="future-work">Future Work</h1>
<p>Use it for realtime localization in Gazebo.</p>
     </div>
     <div class="post-tail-wrapper text-muted">
       <div class="post-meta mb-3">
          <i class="far fa-folder-open fa-fw mr-1"></i>
            <a href='/categories/projects/'>Projects</a>,
            <a href='/categories/diy/'>DIY</a>
       </div>
       <div class="post-tags">
          <i class="fa fa-tags fa-fw mr-1"></i>
          <a href="/tags/atmega328p/"
            class="post-tag no-text-decoration" >atmega328p</a>
          <a href="/tags/game/"
            class="post-tag no-text-decoration" >game</a>
          <a href="/tags/imu/"
            class="post-tag no-text-decoration" >imu</a>
          <a href="/tags/touch/"
            class="post-tag no-text-decoration" >touch</a>
         </div>
       <div class="post-tail-bottom
          d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
         <div class="license-wrapper">
            This post is licensed under
            <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>
            by the author.
         </div>
<div class="share-wrapper">
  <span class="share-label text-muted mr-1">Share</span>
  <span class="share-icons">
        <a href="https://twitter.com/intent/tweet?text=Aerial Navigation in GPS Denied Environments - Jai Krishna&url=https://textzip.github.io/posts/Orthomosaic-SLAM/" data-toggle="tooltip" data-placement="top"
          title="Twitter" target="_blank" rel="noopener" aria-label="Twitter">
          <i class="fa-fw fab fa-twitter"></i>
        </a>
        <a href="https://www.facebook.com/sharer/sharer.php?title=Aerial Navigation in GPS Denied Environments - Jai Krishna&u=https://textzip.github.io/posts/Orthomosaic-SLAM/" data-toggle="tooltip" data-placement="top"
          title="Facebook" target="_blank" rel="noopener" aria-label="Facebook">
          <i class="fa-fw fab fa-facebook-square"></i>
        </a>
        <a href="https://telegram.me/share?text=Aerial Navigation in GPS Denied Environments - Jai Krishna&url=https://textzip.github.io/posts/Orthomosaic-SLAM/" data-toggle="tooltip" data-placement="top"
          title="Telegram" target="_blank" rel="noopener" aria-label="Telegram">
          <i class="fa-fw fab fa-telegram"></i>
        </a>
    <i class="fa-fw fas fa-link small" onclick="copyLink()"
        data-toggle="tooltip" data-placement="top" title="Copy link"></i>
  </span>
</div>
       </div>
     </div>
   </div>
 </div>
<div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down">
 <div class="access">
   <div id="access-lastmod" class="post">
      <span>Recent Update</span>
     <ul class="post-content pl-0 pb-1 ml-1 mt-2">
       <li><a href="/posts/Loco-DRL/">Proprioceptive Locomotion in Unstructured Environments</a>
       <li><a href="/posts/FTG-DRL/">Policy Modulated Trajectory Generation for Quadrupeds</a>
       <li><a href="/posts/NST-DRL/">Neural Style Transfer for Locomotion</a>
       <li><a href="/posts/LIDAR-DRL/">Locomotion with Weighted Belief in Exteroception</a>
       <li><a href="/posts/BiMan-DRL/">Bi-Manual Loco-Manipulation in Quadrupeds for Opening Doors</a>
     </ul>
   </div>
   <div id="access-tags">
      <span>Trending Tags</span>
     <div class="d-flex flex-wrap mt-3 mb-1 mr-3">
        <a class="post-tag" href="/tags/atmega328p/">atmega328p</a>
        <a class="post-tag" href="/tags/imu/">imu</a>
        <a class="post-tag" href="/tags/game/">game</a>
        <a class="post-tag" href="/tags/reinforcement-learning/">reinforcement learning</a>
        <a class="post-tag" href="/tags/bellman/">bellman</a>
        <a class="post-tag" href="/tags/mdp/">mdp</a>
        <a class="post-tag" href="/tags/optimal-value/">optimal value</a>
        <a class="post-tag" href="/tags/touch/">touch</a>
        <a class="post-tag" href="/tags/quadruped/">quadruped</a>
        <a class="post-tag" href="/tags/ros/">ros</a>
     </div>
   </div>
 </div>
    <script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script>
   <div id="toc-wrapper" class="pl-0 pr-4 mb-5">
      <span class="pl-3 pt-2 mb-2">Contents</span>
     <nav id="toc" data-toggle="toc"></nav>
   </div>
</div>
</div>
<div class="row">
 <div class="col-12 col-lg-11 col-xl-8">
   <div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4">
 <div id="related-posts" class="mt-5 mb-2 mb-sm-4">
   <h3 class="pt-2 mt-1 mb-4 ml-1"
      data-toc-skip>Further Reading</h3>
   <div class="card-deck mb-4">
     <div class="card">
        <a href="/posts/COVID19/">
         <div class="card-body">
<em class="timeago small"
    data-ts="1626248600"
    >
  2021-07-14
</em>
           <h3 class="pt-0 mt-1 mb-3" data-toc-skip>Plug-and-Play Oxygen Auto-flow Regulator for Low Flow Oxygen Therapy</h3>
           <div class="text-muted small">
             <p>
A portable, easy to interface device that intelligently controls the oxygen flow rate based on oxygen saturation and other vitals.
This work has been published, please find the full details in ...
             </p>
           </div>
         </div>
        </a>
     </div>
     <div class="card">
        <a href="/posts/QDD/">
         <div class="card-body">
<em class="timeago small"
    data-ts="1634391800"
    >
  2021-10-16
</em>
           <h3 class="pt-0 mt-1 mb-3" data-toc-skip>Quasi Direct Drive Actuator</h3>
           <div class="text-muted small">
             <p>
An open-source Quasi Direct Drive Actuator for use in locomotion centric projects.
Note: The project is ongoing, the blog post will be updated as the project progresses.
Hardware
  400kv BLDC
...
             </p>
           </div>
         </div>
        </a>
     </div>
     <div class="card">
        <a href="/posts/CoAxial-Bicopter/">
         <div class="card-body">
<em class="timeago small"
    data-ts="1634564600"
    >
  2021-10-18
</em>
           <h3 class="pt-0 mt-1 mb-3" data-toc-skip>Co-Axial Bi-Copter</h3>
           <div class="text-muted small">
             <p>
A project to explore control strategies for thrust vector control of an
co-axial propeller with four control surfaces.
Note: The project is in progress, further details/sections will be added as...
             </p>
           </div>
         </div>
        </a>
     </div>
   </div>
 </div>
<div class="post-navigation d-flex justify-content-between">
  <a href="/posts/CoAxial-Bicopter/" class="btn btn-outline-primary"
    prompt="Older">
   <p>Co-Axial Bi-Copter</p>
  </a>
  <a href="/posts/POV-lightsaber/" class="btn btn-outline-primary"
    prompt="Newer">
   <p>POV - Lightsaber</p>
  </a>
</div>
    <script src="https://utteranc.es/client.js"
        repo="TextZip/textzip.github.io"
        issue-term="title"
        theme="dark-blue"
        crossorigin="anonymous"
        async>
    </script>
   </div>
 </div>
</div>
<footer class="d-flex w-100 justify-content-center">
 <div class="d-flex justify-content-between align-items-center">
   <div class="footer-left">
     <p class="mb-0">
        © 2025
        <a href="https://github.com/TextZip">Bandi Jai Krishna</a>.
        <span data-toggle="tooltip" data-placement="top"
          title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span>
     </p>
   </div>
   <div class="footer-right">
     <p class="mb-0">
        Powered by
        <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>
        with
        <a href="https://github.com/cotes2020/jekyll-theme-chirpy"
          target="_blank" rel="noopener">Chirpy</a>
        theme.
     </p>
   </div>
 </div>
</footer>
     </div>
<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
 <div class="col-12 col-sm-11 post-content">
   <div id="search-hints">
     <h4 class="text-muted mb-4">Trending Tags</h4>
        <a class="post-tag" href="/tags/atmega328p/">atmega328p</a>
        <a class="post-tag" href="/tags/imu/">imu</a>
        <a class="post-tag" href="/tags/game/">game</a>
        <a class="post-tag" href="/tags/reinforcement-learning/">reinforcement learning</a>
        <a class="post-tag" href="/tags/bellman/">bellman</a>
        <a class="post-tag" href="/tags/mdp/">mdp</a>
        <a class="post-tag" href="/tags/optimal-value/">optimal value</a>
        <a class="post-tag" href="/tags/touch/">touch</a>
        <a class="post-tag" href="/tags/quadruped/">quadruped</a>
        <a class="post-tag" href="/tags/ros/">ros</a>
   </div>
   <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
 </div>
</div>
   </div>
   <div id="mask"></div>
    <a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button">
      <i class="fas fa-angle-up"></i>
    </a>
<script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script>
<script>
SimpleJekyllSearch({
  searchInput: document.getElementById('search-input'),
  resultsContainer: document.getElementById('search-results'),
  json: '/assets/js/data/search.json',
  searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0">  <a href="https://textzip.github.io{url}">{title}</a> <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">    {categories}    {tags} </div><p>{snippet}</p></div>',
  noResultsText: '<p class="mt-5">Oops! No result founds.</p>',
  templateMiddleware: function(prop, value, template) {
    if (prop === 'categories') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
      }
    }
    if (prop === 'tags') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
      }
    }
  }
});
</script>
  <script src="/assets/js/slider/ideal-image-slider.min.js"></script>
  <script src="/assets/js/slider/iis-bullet-nav.js"></script>
  <script src="/assets/js/slider/iis-captions.js"></script>
  <script>
  var orthoslam = new IdealImageSlider.Slider({
      selector: '#orthoslam',
      height: 600,
      interval: 4000,
      effect: 'slide',
      keyboardNav: true,
      });
    orthoslam.addCaptions();
    orthoslam.start();
  </script>
  
