---
title: Locomotion with Weighted Belief in Exteroception
date: 2024-04-12 13:13:20 +/-0530
categories: [Projects, Quadrupeds]
tags: [reinforcement learning, lidar, quadruped] # TAG names should always be lowercase
math: true
image: /assets/img/LIDAR-DRL/lidar_points_cover.png
hidden: false
---

![Image1](/assets/img/LIDAR-DRL/lidar_student.png){: .shadow}

This project goes over the integration of elevation maps (typically obtained from LIDARs/Depth Cameras) into the locomotion pipeline and the intricacies involved in this process. We will try to reimplement and modify a pretty well known paper that executes this idea of using exteroceptive sensors for locomotion.

<!--The following work has been done during my time at the [CNRS-AIST JRL (Joint Robotics Laboratory), IRL, Japan](https://unit.aist.go.jp/jrl-22022/index_en.html) for my undergraduate thesis under the supervision of [Dr. Mitsuharu Morisawa](https://unit.aist.go.jp/jrl-22022/en/members/member-morisawa.html) with support from [Rohan Singh](https://unit.aist.go.jp/jrl-22022/en/members/member-singh.html).-->

<iframe width="640" height="385" src="https://youtube.com/embed/Qu5r9823Za0" frameborder="0" allowfullscreen></iframe>

> **Note:** Detailed results and video clips can be found in the [Results](#results) section below.

To be updated soon
